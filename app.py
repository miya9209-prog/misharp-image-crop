# app.py
# -*- coding: utf-8 -*-

import io
import re
import zipfile
from dataclasses import dataclass
from typing import List, Tuple, Optional

import numpy as np
import requests
import streamlit as st
from bs4 import BeautifulSoup
from PIL import Image

# âœ… OpenCV (ì‚¬ê° ìƒí’ˆì»· ì˜¤ë¸Œì íŠ¸ ê°ì§€ìš©)
import cv2

# -----------------------------
# ê¸°ë³¸ ì„¤ì •
# -----------------------------
st.set_page_config(
    page_title="MISHARP ì´ë¯¸ì§€ ì¶”ì¶œìƒì„±ê¸°",
    page_icon="ğŸ§©",
    layout="wide",
)

USER_AGENT = (
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
    "AppleWebKit/537.36 (KHTML, like Gecko) "
    "Chrome/122.0.0.0 Safari/537.36"
)

WHITE_THR = 245  # í°ìƒ‰ íŒì • ì„ê³„ê°’
EDGE_WHITE_STRIP_MIN_PX = 5  # âœ… 5px ì´ìƒ í°ì¤„ì€ ì—¬ë°±ìœ¼ë¡œ ì²˜ë¦¬


# -----------------------------
# ë°ì´í„° êµ¬ì¡°
# -----------------------------
@dataclass
class CutItem:
    idx: int
    pil: Image.Image
    excluded_auto: bool = False
    excluded_manual: bool = False
    reason: str = ""


# -----------------------------
# ìœ í‹¸
# -----------------------------
def safe_filename(name: str) -> str:
    name = (name or "").strip()
    name = re.sub(r"[\\/:*?\"<>|]+", "_", name)
    name = re.sub(r"\s+", " ", name).strip()
    return name[:120] if len(name) > 120 else name


def pil_to_bytes_jpg(img: Image.Image, quality: int = 95) -> bytes:
    buf = io.BytesIO()
    img.save(buf, format="JPEG", quality=quality, optimize=True)
    return buf.getvalue()


def make_download_zip(files: List[Tuple[str, bytes]]) -> bytes:
    buf = io.BytesIO()
    with zipfile.ZipFile(buf, "w", compression=zipfile.ZIP_DEFLATED) as zf:
        for fname, data in files:
            zf.writestr(fname, data)
    return buf.getvalue()


def center_crop_to_aspect(img: Image.Image, target_aspect: float) -> Image.Image:
    """ì™œê³¡ ì—†ì´ ê°€ìš´ë° ê¸°ì¤€ìœ¼ë¡œ ë¹„ìœ¨ ë§ì¶”ê¸°(ì˜ë¼ë‚´ê¸°)."""
    w, h = img.size
    if w <= 0 or h <= 0:
        return img

    cur_aspect = w / float(h)
    if abs(cur_aspect - target_aspect) < 1e-6:
        return img

    if cur_aspect > target_aspect:
        new_w = int(round(h * target_aspect))
        new_w = max(1, min(new_w, w))
        left = (w - new_w) // 2
        return img.crop((left, 0, left + new_w, h))

    new_h = int(round(w / target_aspect))
    new_h = max(1, min(new_h, h))
    top = (h - new_h) // 2
    return img.crop((0, top, w, top + new_h))


# -----------------------------
# âœ… 5px ì´ìƒ í°ì¤„ ì œê±° (ìƒ/í•˜/ì¢Œ/ìš°)
# -----------------------------
def _is_row_white(arr_rgb: np.ndarray, y: int, thr: int = WHITE_THR, ratio: float = 0.995) -> bool:
    row = arr_rgb[y, :, :]
    white = (row[:, 0] >= thr) & (row[:, 1] >= thr) & (row[:, 2] >= thr)
    return float(white.mean()) >= ratio


def _is_col_white(arr_rgb: np.ndarray, x: int, thr: int = WHITE_THR, ratio: float = 0.995) -> bool:
    col = arr_rgb[:, x, :]
    white = (col[:, 0] >= thr) & (col[:, 1] >= thr) & (col[:, 2] >= thr)
    return float(white.mean()) >= ratio


def trim_edge_white_strips(img: Image.Image, thr: int = WHITE_THR, min_strip: int = EDGE_WHITE_STRIP_MIN_PX) -> Image.Image:
    """ê°€ì¥ìë¦¬(ìƒ/í•˜/ì¢Œ/ìš°)ì—ì„œ 'ì—°ì†ëœ í°ì¤„'ì´ min_strip px ì´ìƒì´ë©´ ê·¸ êµ¬ê°„ì„ ì˜ë¼ëƒ„."""
    if img.mode != "RGB":
        img = img.convert("RGB")
    arr = np.array(img)
    h, w = arr.shape[:2]

    top = 0
    while top < h and _is_row_white(arr, top, thr=thr):
        top += 1
    if top < min_strip:
        top = 0

    bottom = h - 1
    while bottom >= 0 and _is_row_white(arr, bottom, thr=thr):
        bottom -= 1
    # bottomì€ "ë§ˆì§€ë§‰ ë¹„-í°ì¤„" ì¸ë±ìŠ¤
    bottom_cut = h - 1 - bottom
    if bottom_cut < min_strip:
        bottom = h - 1

    left = 0
    while left < w and _is_col_white(arr, left, thr=thr):
        left += 1
    if left < min_strip:
        left = 0

    right = w - 1
    while right >= 0 and _is_col_white(arr, right, thr=thr):
        right -= 1
    right_cut = w - 1 - right
    if right_cut < min_strip:
        right = w - 1

    # ìœ íš¨ ë²”ìœ„ ì²´í¬
    if right - left < 10 or bottom - top < 10:
        return img

    return img.crop((left, top, right + 1, bottom + 1))


def trim_white_margin_tight(img: Image.Image, thr: int = WHITE_THR) -> Image.Image:
    """í° ë°°ê²½ ì—¬ë°± ì œê±°(íƒ€ì´íŠ¸). pad=0 ëŠë‚Œìœ¼ë¡œ ìµœëŒ€í•œ ì—¬ë°± ì—†ì´."""
    if img.mode != "RGB":
        img = img.convert("RGB")

    arr = np.array(img)
    is_white = (arr[:, :, 0] >= thr) & (arr[:, :, 1] >= thr) & (arr[:, :, 2] >= thr)
    non_white = ~is_white

    if not np.any(non_white):
        return img

    ys, xs = np.where(non_white)
    y0, y1 = int(ys.min()), int(ys.max())
    x0, x1 = int(xs.min()), int(xs.max())

    out = img.crop((x0, y0, x1 + 1, y1 + 1))
    # âœ… ê°€ì¥ìë¦¬ í°ì¤„(5px ì´ìƒ) ì¶”ê°€ ì œê±°
    out = trim_edge_white_strips(out, thr=thr, min_strip=EDGE_WHITE_STRIP_MIN_PX)
    return out


# -----------------------------
# âœ… ì‚¬ê° "ìƒí’ˆì»· ì˜¤ë¸Œì íŠ¸" ê°ì§€ â†’ ê°ê° ì˜ë¼ë‚´ê¸°
# -----------------------------
def detect_rect_photo_boxes(img: Image.Image) -> List[Tuple[int, int, int, int]]:
    """
    í° ë°°ê²½ ê¸°ë°˜ ìƒì„¸í˜ì´ì§€ì—ì„œ 'ì‚¬ì§„(ì‚¬ê° ì˜¤ë¸Œì íŠ¸)'ë¡œ ë³´ì´ëŠ” ì˜ì—­ì„ ê²€ì¶œ.
    ë°˜í™˜: (x0,y0,x1,y1) ë¦¬ìŠ¤íŠ¸
    """
    if img.mode != "RGB":
        img = img.convert("RGB")

    arr = np.array(img)
    h, w = arr.shape[:2]

    # í°ìƒ‰ ë°°ê²½ vs ë¹„-í°ìƒ‰ ë¶„ë¦¬
    gray = cv2.cvtColor(arr, cv2.COLOR_RGB2GRAY)

    # thrë³´ë‹¤ ë°ìœ¼ë©´ ë°°ê²½(í°ìƒ‰)ë¡œ ë³´ê³ , ì–´ë‘ìš´ ìª½ì„ ì „ê²½ìœ¼ë¡œ
    # -> ì „ê²½(ìƒí’ˆì»·, ëª¨ë¸ì»·, í…ìŠ¤íŠ¸ í¬í•¨)ì„ 1ë¡œ ë§Œë“¤ê¸°
    _, bin_inv = cv2.threshold(gray, WHITE_THR, 255, cv2.THRESH_BINARY_INV)

    # ì‘ì€ ì  ë…¸ì´ì¦ˆ ì œê±° / ì‚¬ê° ë‚´ë¶€ ì±„ì›€
    kernel = np.ones((5, 5), np.uint8)
    bin_inv = cv2.morphologyEx(bin_inv, cv2.MORPH_CLOSE, kernel, iterations=2)
    bin_inv = cv2.morphologyEx(bin_inv, cv2.MORPH_OPEN, kernel, iterations=1)

    contours, _ = cv2.findContours(bin_inv, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    boxes: List[Tuple[int, int, int, int]] = []
    min_area = max(200 * 200, int((w * h) * 0.01))  # ë„ˆë¬´ ì‘ì€ ê±´ ì œì™¸
    max_area = int((w * h) * 0.98)                  # í™”ë©´ ê±°ì˜ ì „ì²´ëŠ” ì œì™¸(ë¡± ì´ë¯¸ì§€ ì „ì²´ ë“±)

    for cnt in contours:
        x, y, ww, hh = cv2.boundingRect(cnt)
        area = ww * hh
        if area < min_area or area > max_area:
            continue

        # ë„ˆë¬´ ì–‡ì€ ë /ì„ í˜• ì œê±°
        if ww < 220 or hh < 220:
            continue

        # í™”ë©´ ê°€ì¥ìë¦¬ í…Œë‘ë¦¬ë§Œ ì¡íˆëŠ” ê²½ìš° ì™„í™”
        pad = 2
        x0 = max(0, x - pad)
        y0 = max(0, y - pad)
        x1 = min(w, x + ww + pad)
        y1 = min(h, y + hh + pad)

        boxes.append((x0, y0, x1, y1))

    # âœ… ì •ë ¬: ìœ„â†’ì•„ë˜, ì¢Œâ†’ìš°
    boxes = sorted(boxes, key=lambda b: (b[1], b[0]))

    # âœ… ê²¹ì¹¨ ì œê±°(í° ë°•ìŠ¤ê°€ ì‘ì€ ë°•ìŠ¤ë¥¼ ì§‘ì–´ì‚¼í‚¤ëŠ” ì¼€ì´ìŠ¤)
    filtered: List[Tuple[int, int, int, int]] = []
    for b in boxes:
        x0, y0, x1, y1 = b
        keep = True
        for bb in filtered:
            xx0, yy0, xx1, yy1 = bb
            # í¬í•¨ ê´€ê³„(ê±°ì˜ ì™„ì „ í¬í•¨)ì´ë©´ ì‘ì€ ê²ƒì„ ìš°ì„  ì‚´ë¦¬ê³  í° ê²ƒì„ ë²„ë¦¼
            if x0 >= xx0 and y0 >= yy0 and x1 <= xx1 and y1 <= yy1:
                keep = False
                break
        if keep:
            filtered.append(b)

    return filtered


def split_into_photo_objects(img: Image.Image) -> List[Image.Image]:
    """
    ì…ë ¥ ì´ë¯¸ì§€(ë¡± ì„¸ê·¸ë¨¼íŠ¸ í¬í•¨)ì—ì„œ 'ì‚¬ê° ìƒí’ˆì»· ì˜¤ë¸Œì íŠ¸'ë¥¼ ëª¨ë‘ ì°¾ì•„
    ê°ê° ì—¬ë°± ì—†ì´ ì˜ë¼ ë°˜í™˜.
    - ê°ì§€ê°€ ì•ˆ ë˜ë©´: ì›ë³¸(ì—¬ë°± ì œê±°) 1ì¥ ë°˜í™˜
    """
    base = trim_edge_white_strips(img, thr=WHITE_THR, min_strip=EDGE_WHITE_STRIP_MIN_PX)

    boxes = detect_rect_photo_boxes(base)

    # ê°ì§€ëœ ì‚¬ê° ì˜¤ë¸Œì íŠ¸ê°€ ì—†ìœ¼ë©´ ê¸°ì¡´ ë°©ì‹(íƒ€ì´íŠ¸ íŠ¸ë¦¼)ìœ¼ë¡œ 1ì¥
    if not boxes:
        only = trim_white_margin_tight(base, thr=WHITE_THR)
        return [only]

    out: List[Image.Image] = []
    for (x0, y0, x1, y1) in boxes:
        crop = base.crop((x0, y0, x1, y1))
        crop = trim_white_margin_tight(crop, thr=WHITE_THR)
        # ë„ˆë¬´ ì‘ì€ ì¡°ê°ì€ ì œì™¸
        if crop.size[0] < 300 or crop.size[1] < 240:
            continue
        out.append(crop)

    # ê·¸ë˜ë„ ë„ˆë¬´ ì ê²Œ ë‚˜ì˜¤ë©´(ì˜¤ê²€ì¶œ) fallback
    if len(out) == 0:
        only = trim_white_margin_tight(base, thr=WHITE_THR)
        return [only]

    return out


# -----------------------------
# ê¸´ ìƒì„¸í˜ì´ì§€(ë¡± ì´ë¯¸ì§€) ëŒ€ëµ ë¶„í• (ê°€ë¡œì¤„ ì—¬ë°± ê¸°ì¤€) + ê° êµ¬ê°„ì—ì„œ ì˜¤ë¸Œì íŠ¸ ì¶”ì¶œ
# -----------------------------
def row_nonwhite_ratio(arr_rgb: np.ndarray, white_thr: int = WHITE_THR) -> np.ndarray:
    is_white = (arr_rgb[:, :, 0] >= white_thr) & (arr_rgb[:, :, 1] >= white_thr) & (arr_rgb[:, :, 2] >= white_thr)
    non_white = ~is_white
    return non_white.mean(axis=1).astype(np.float32)


def smooth_1d(x: np.ndarray, k: int = 31) -> np.ndarray:
    if k <= 1:
        return x
    k = int(k)
    k = k if k % 2 == 1 else k + 1
    pad = k // 2
    xp = np.pad(x, (pad, pad), mode="edge")
    kernel = np.ones(k, dtype=np.float32) / k
    return np.convolve(xp, kernel, mode="valid")


def find_separator_gaps(ratio: np.ndarray, gap_thr: float = 0.006, min_gap: int = 20) -> List[Tuple[int, int]]:
    low = ratio <= gap_thr
    gaps = []
    start = None
    for i, v in enumerate(low):
        if v and start is None:
            start = i
        elif (not v) and start is not None:
            end = i - 1
            if end - start + 1 >= min_gap:
                gaps.append((start, end))
            start = None
    if start is not None:
        end = len(low) - 1
        if end - start + 1 >= min_gap:
            gaps.append((start, end))
    return gaps


def segment_long_detail_image(img: Image.Image) -> List[Image.Image]:
    """
    1) ë¡± ì´ë¯¸ì§€ë¥¼ í° ì—¬ë°± êµ¬ê°„ ê¸°ì¤€ìœ¼ë¡œ í° ë©ì–´ë¦¬ë¡œ ë¶„ë¦¬
    2) ê° ë©ì–´ë¦¬ì—ì„œ 'ì‚¬ê° ìƒí’ˆì»· ì˜¤ë¸Œì íŠ¸'ë¥¼ ëª¨ë‘ ì°¾ì•„ ê°ê° ì €ì¥
    """
    if img.mode != "RGB":
        img = img.convert("RGB")

    # ë¨¼ì € ê°€ì¥ìë¦¬ í°ì¤„ ì œê±°
    img = trim_edge_white_strips(img, thr=WHITE_THR, min_strip=EDGE_WHITE_STRIP_MIN_PX)

    arr = np.array(img)
    r = row_nonwhite_ratio(arr, white_thr=WHITE_THR)
    r = smooth_1d(r, k=31)

    gaps = find_separator_gaps(r, gap_thr=0.006, min_gap=20)

    h = arr.shape[0]
    cuts = []
    prev_end = -1
    for (g0, g1) in gaps:
        seg_top = prev_end + 1
        seg_bot = g0 - 1
        if seg_bot - seg_top + 1 >= 120:
            cuts.append((seg_top, seg_bot))
        prev_end = g1

    if prev_end < h - 1:
        seg_top = prev_end + 1
        seg_bot = h - 1
        if seg_bot - seg_top + 1 >= 120:
            cuts.append((seg_top, seg_bot))

    out: List[Image.Image] = []
    w = img.size[0]
    for (t, b) in cuts:
        seg = img.crop((0, t, w, b + 1))
        seg = trim_edge_white_strips(seg, thr=WHITE_THR, min_strip=EDGE_WHITE_STRIP_MIN_PX)

        # âœ… í•µì‹¬: ì„¸ê·¸ë¨¼íŠ¸ ì•ˆì—ì„œ 'ì‚¬ê° ìƒí’ˆì»·'ì„ ê°ê° ì¶”ì¶œ
        objs = split_into_photo_objects(seg)
        for o in objs:
            if o.size[1] < 220 or o.size[0] < 300:
                continue
            out.append(o)

    return out


# -----------------------------
# í…ìŠ¤íŠ¸/ë¡œê³  ìë™ ì œì™¸(ê¸°ì¡´ ë¡œì§ ìœ ì§€, ì…ë ¥ì€ ë” íƒ€ì´íŠ¸í•´ì§„ ì»· ê¸°ì¤€)
# -----------------------------
def looks_like_text_card(img: Image.Image) -> Tuple[bool, str]:
    if img.mode != "RGB":
        img = img.convert("RGB")

    w, h = img.size
    arr = np.array(img).astype(np.uint8)

    white = (arr[:, :, 0] >= WHITE_THR) & (arr[:, :, 1] >= WHITE_THR) & (arr[:, :, 2] >= WHITE_THR)
    white_ratio = float(white.mean())

    gray = (0.299 * arr[:, :, 0] + 0.587 * arr[:, :, 1] + 0.114 * arr[:, :, 2]).astype(np.float32)
    dark_ratio = float((gray < 80).mean())

    std = float(arr.reshape(-1, 3).std(axis=0).mean())

    if h < 220 and white_ratio > 0.75 and dark_ratio > 0.002:
        return True, "í…ìŠ¤íŠ¸ ì•ˆë‚´(ì–‡ì€ ë )ë¡œ ì¶”ì •"

    if white_ratio > 0.70 and 0.002 < dark_ratio < 0.18 and std < 35:
        return True, "í…ìŠ¤íŠ¸/íƒ€ì´í‹€ ì»·ìœ¼ë¡œ ì¶”ì •"

    if (h < 500 and w < 900) and white_ratio > 0.40 and dark_ratio < 0.10:
        return True, "ì•„ì´ì½˜/ë¡œê³ ì„± ì´ë¯¸ì§€ë¡œ ì¶”ì •"

    return False, ""


def apply_crop_mode(img: Image.Image, mode: str) -> Image.Image:
    """4ê°€ì§€ ìë¥´ê¸° ëª¨ë“œ ì ìš©."""
    base = trim_white_margin_tight(img, thr=WHITE_THR)

    if mode == "ì´ë¯¸ì§€ ê·¸ëŒ€ë¡œ ìë¥´ê¸°":
        return base

    if mode == "ì¸ìŠ¤íƒ€ê·¸ë¨ í”¼ë“œ ê·œê²©(4:5)":
        out = center_crop_to_aspect(base, 4 / 5)
        return out.resize((1080, 1350), Image.LANCZOS)

    if mode == "ì •ë°©í˜•(1:1)":
        out = center_crop_to_aspect(base, 1.0)
        return out.resize((1080, 1080), Image.LANCZOS)

    if mode == "ìˆí¼ê·œê²©(900x1600)":
        out = center_crop_to_aspect(base, 900 / 1600)
        return out.resize((900, 1600), Image.LANCZOS)

    return base


# -----------------------------
# URLì—ì„œ "ë³¸ë¬¸ ìƒì„¸ì´ë¯¸ì§€" í›„ë³´ë§Œ ì°¾ê¸°
# -----------------------------
def normalize_url(url: str) -> str:
    url = (url or "").strip()
    if not url:
        return url
    if not re.match(r"^https?://", url, re.I):
        url = "https://" + url
    return url


def fetch_html(url: str, timeout: int = 15) -> str:
    headers = {"User-Agent": USER_AGENT}
    r = requests.get(url, headers=headers, timeout=timeout)
    r.raise_for_status()
    return r.text


def is_image_url(u: str) -> bool:
    u_low = u.lower()
    return any(u_low.endswith(ext) for ext in [".jpg", ".jpeg", ".png", ".webp", ".gif"])


def absolutize(base_url: str, src: str) -> str:
    src = (src or "").strip()
    if src.startswith("//"):
        return "https:" + src
    if src.startswith("http://") or src.startswith("https://"):
        return src
    if src.startswith("/"):
        m = re.match(r"^(https?://[^/]+)", base_url)
        return (m.group(1) if m else base_url.rstrip("/")) + src
    return base_url.rstrip("/") + "/" + src.lstrip("/")


def pick_body_image_urls_from_html(product_url: str, html: str) -> List[str]:
    soup = BeautifulSoup(html, "html.parser")

    selectors = [
        "#prdDetail", "#prdDetailContent", "#prdDetailCont",
        "#productDetail", "#product_detail", "#contents",
        ".prdDetail", ".prdDetailContent", ".productDetail",
        "#tabProductDetail", "#tabDetail",
        "div[id*='prdDetail']", "div[class*='prdDetail']",
    ]

    img_urls: List[str] = []
    for sel in selectors:
        node = soup.select_one(sel)
        if not node:
            continue
        for img in node.select("img"):
            src = img.get("src") or img.get("data-src") or img.get("ec-data-src")
            if not src:
                continue
            src = absolutize(product_url, src)
            if is_image_url(src):
                img_urls.append(src)

    img_urls = list(dict.fromkeys(img_urls))

    if not img_urls:
        all_imgs = soup.select("img")
        tmp = []
        for img in all_imgs:
            src = img.get("src") or img.get("data-src") or img.get("ec-data-src")
            if not src:
                continue
            src = absolutize(product_url, src)
            if not is_image_url(src):
                continue

            s_low = src.lower()
            if any(k in s_low for k in ["icon", "logo", "sprite", "common", "btn", "banner"]):
                continue

            tmp.append(src)
        img_urls = list(dict.fromkeys(tmp))

    return img_urls


def download_image(url: str, timeout: int = 20) -> Optional[Image.Image]:
    headers = {"User-Agent": USER_AGENT}
    try:
        r = requests.get(url, headers=headers, timeout=timeout)
        r.raise_for_status()
        img = Image.open(io.BytesIO(r.content))
        return img.convert("RGB")
    except Exception:
        return None


def fetch_detail_images_from_product_url(product_url: str) -> List[Image.Image]:
    html = fetch_html(product_url)
    candidates = pick_body_image_urls_from_html(product_url, html)

    downloaded: List[Image.Image] = []
    for u in candidates:
        im = download_image(u)
        if im is not None:
            downloaded.append(im)

    # ê¸´ ìƒì„¸ì´ë¯¸ì§€ ìš°ì„ 
    long_imgs = []
    for im in downloaded:
        w, h = im.size
        if h > w * 2 and h > 2000:
            long_imgs.append(im)

    if not long_imgs:
        big_imgs = []
        for im in downloaded:
            w, h = im.size
            if min(w, h) >= 700 and (h >= 900 or w >= 900):
                big_imgs.append(im)
        long_imgs = big_imgs[:30]

    return long_imgs


def guess_base_name_from_url(url: str) -> str:
    m = re.search(r"product_no=(\d+)", url)
    if m:
        return f"product_{m.group(1)}"
    base = re.sub(r"[?#].*$", "", url).rstrip("/").split("/")[-1]
    return safe_filename(base or "misharp_detail")


# -----------------------------
# ì»· ìƒì„± íŒŒì´í”„ë¼ì¸
# -----------------------------
def build_items_from_sources(source_images: List[Image.Image], auto_exclude_text: bool = True) -> List[CutItem]:
    all_items: List[CutItem] = []
    global_idx = 1

    for img in source_images:
        w, h = img.size

        # âœ… ë¡± ì´ë¯¸ì§€ë©´: (1) ì„¸ê·¸ë¨¼íŠ¸ â†’ (2) ì„¸ê·¸ë¨¼íŠ¸ ì•ˆì˜ ì‚¬ê° ì˜¤ë¸Œì íŠ¸ ê°ê° ì¶”ì¶œ
        if h > w * 2 and h > 2000:
            extracted = segment_long_detail_image(img)
        else:
            # âœ… ë¡±ì´ ì•„ë‹ˆì–´ë„: ì´ë¯¸ì§€ ì•ˆì— ì‚¬ê° ì˜¤ë¸Œì íŠ¸ê°€ ì—¬ëŸ¬ ê°œë©´ ê°ê° ë¶„ë¦¬
            extracted = split_into_photo_objects(img)

        for cut in extracted:
            cut = trim_white_margin_tight(cut, thr=WHITE_THR)

            ex = False
            reason = ""
            if auto_exclude_text:
                ex, reason = looks_like_text_card(cut)

            all_items.append(CutItem(idx=global_idx, pil=cut, excluded_auto=ex, reason=reason))
            global_idx += 1

    # ì•ˆì „ì¥ì¹˜: ë„ˆë¬´ ì‘ì€ ì¡°ê° ìë™ ì œì™¸
    for it in all_items:
        ww, hh = it.pil.size
        if ww < 300 or hh < 240:
            it.excluded_auto = True
            it.reason = it.reason or "ë„ˆë¬´ ì‘ì€ ì´ë¯¸ì§€(ì¡°ê°)ë¡œ ì œì™¸"

    return all_items


# -----------------------------
# UI ìŠ¤íƒ€ì¼ (ì‹¬í”Œ/ì„¸ë ¨/ì§ê´€ + ì œëª© ì˜ë¦¼ ë°©ì§€)
# -----------------------------
st.markdown(
    """
<style>
/* ì „ì²´ ì—¬ë°±(ìƒë‹¨ ì œëª© ì˜ë¦¼ ë°©ì§€) */
.block-container { padding-top: 2.2rem; padding-bottom: 2.6rem; max-width: 1280px; }

/* íƒ€ì´í¬ */
h1 { margin-top: 0 !important; letter-spacing: -0.3px; }
h2 { margin-top: 1.4rem; letter-spacing: -0.2px; }
p, label, div, span { letter-spacing: -0.1px; }

/* ì¹´ë“œ/êµ¬ë¶„ì„  */
.card { border: 1px solid rgba(0,0,0,0.08); border-radius: 16px; padding: 16px; background: rgba(255,255,255,0.02); }
.hr { height: 1px; background: rgba(255,255,255,0.10); margin: 18px 0; }

.small-note { font-size: 12px; opacity: 0.72; line-height: 1.6; }
.footer-note { font-size: 11px; opacity: 0.72; line-height: 1.65; padding-top: 18px; }

/* ë²„íŠ¼/ì…ë ¥ ê°„ê²© */
.stButton button { padding: 0.8rem 1rem; border-radius: 14px; }
</style>
""",
    unsafe_allow_html=True,
)

st.title("ğŸ§© MISHARP ì´ë¯¸ì§€ ì¶”ì¶œìƒì„±ê¸°")
st.caption("MISHARP IMAGE GENERATOR V1")

st.markdown('<div class="hr"></div>', unsafe_allow_html=True)

# -----------------------------
# 1) ì…ë ¥
# -----------------------------
st.subheader("1) ì…ë ¥")
colA, colB = st.columns([1.25, 1])

with colA:
    input_type = st.radio("ì…ë ¥ ì„ íƒ", ["ìƒí’ˆ URL", "ìƒì„¸í˜ì´ì§€ JPG ì—…ë¡œë“œ"], horizontal=True)

    product_url = ""
    uploaded_files = None

    if input_type == "ìƒí’ˆ URL":
        product_url = st.text_input(
            "ë¯¸ìƒµ ìƒí’ˆ URL",
            placeholder="https://misharp.co.kr/product/detail.html?product_no=XXXXX ...",
        )
        st.markdown(
            '<div class="small-note">â€» URL ì…ë ¥ ì‹œ: <b>ìƒí’ˆ ìƒì„¸ HTMLì—ì„œ ë³¸ë¬¸ ìƒì„¸ì´ë¯¸ì§€ í›„ë³´ë§Œ</b> ì„ ë³„í•´ ì²˜ë¦¬í•©ë‹ˆë‹¤.</div>',
            unsafe_allow_html=True,
        )
    else:
        uploaded_files = st.file_uploader(
            "ìƒì„¸í˜ì´ì§€ JPG ì—…ë¡œë“œ (ì—¬ëŸ¬ ì¥ ê°€ëŠ¥)",
            type=["jpg", "jpeg"],
            accept_multiple_files=True,
            help="ê¸´ ìƒì„¸í˜ì´ì§€ ì´ë¯¸ì§€ 1ì¥ ë˜ëŠ” ì—¬ëŸ¬ ì¥ì„ ì˜¬ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
        )

with colB:
    # -----------------------------
    # 2) ìë¥´ê¸° ì˜µì…˜
    # -----------------------------
    st.subheader("2) ìë¥´ê¸° ì˜µì…˜")
    crop_mode = st.selectbox(
        "ìë¥´ê¸° ëª¨ë“œ",
        [
            "ì´ë¯¸ì§€ ê·¸ëŒ€ë¡œ ìë¥´ê¸°",
            "ì¸ìŠ¤íƒ€ê·¸ë¨ í”¼ë“œ ê·œê²©(4:5)",
            "ì •ë°©í˜•(1:1)",
            "ìˆí¼ê·œê²©(900x1600)",
        ],
        index=0,
    )

    auto_exclude_text = st.checkbox("í…ìŠ¤íŠ¸/íƒ€ì´í‹€/ë¡œê³  ì»· ìë™ ì œì™¸", value=True)
    st.markdown(
        '<div class="small-note">â€» ì•„ë˜ 3)ì—ì„œ ìˆ˜ë™ ì²´í¬ë¡œ ì œì™¸/í¬í•¨ì„ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</div>',
        unsafe_allow_html=True,
    )

st.markdown('<div class="hr"></div>', unsafe_allow_html=True)

run = st.button("âœ… ë³¸ë¬¸ ìƒí’ˆì»· ì¶”ì¶œí•˜ê¸°", type="primary", use_container_width=True)

if run:
    with st.spinner("ì´ë¯¸ì§€ ìˆ˜ì§‘/ë¶„ì„ ì¤‘..."):
        base_name = "misharp_detail"
        source_images: List[Image.Image] = []

        if input_type == "ìƒí’ˆ URL":
            product_url = normalize_url(product_url)
            if not product_url:
                st.error("ìƒí’ˆ URLì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
                st.stop()

            base_name = guess_base_name_from_url(product_url)
            imgs = fetch_detail_images_from_product_url(product_url)

            if not imgs:
                st.error("ë³¸ë¬¸ ìƒì„¸ì´ë¯¸ì§€ë¥¼ ì°¾ì§€ ëª»í–ˆì–´ìš”. (ì ‘ê·¼ ì œí•œ/ë³¸ë¬¸ ì´ë¯¸ì§€ê°€ ë‹¤ë¥¸ ë°©ì‹ì¼ ìˆ˜ ìˆìŒ)")
                st.stop()

            source_images = imgs

        else:
            if not uploaded_files or len(uploaded_files) == 0:
                st.error("ìƒì„¸í˜ì´ì§€ JPGë¥¼ 1ì¥ ì´ìƒ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
                st.stop()

            first_name = uploaded_files[0].name
            base_name = safe_filename(re.sub(r"\.(jpg|jpeg)$", "", first_name, flags=re.I)) or "misharp_detail"

            for f in uploaded_files:
                try:
                    im = Image.open(f).convert("RGB")
                    source_images.append(im)
                except Exception:
                    continue

            if not source_images:
                st.error("ì—…ë¡œë“œí•œ íŒŒì¼ì„ ì´ë¯¸ì§€ë¡œ ì½ì§€ ëª»í–ˆì–´ìš”.")
                st.stop()

        items = build_items_from_sources(source_images, auto_exclude_text=auto_exclude_text)

        if not items:
            st.error("ì¶”ì¶œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            st.stop()

        st.session_state["cuts_base_name"] = base_name
        st.session_state["cuts_crop_mode"] = crop_mode
        st.session_state["cuts_items"] = items

        # zip ìºì‹œ ì œê±°
        st.session_state.pop("dl_zip", None)
        st.session_state.pop("dl_zip_name", None)

    st.success(f"ì¶”ì¶œ ì™„ë£Œ! (ì´ {len(items)}ê°œ í›„ë³´) ì•„ë˜ 3)ì—ì„œ ë¯¸ë¦¬ë³´ê¸°/ì œì™¸/ë‹¤ìš´ë¡œë“œë¥¼ ì§„í–‰í•˜ì„¸ìš”.")

st.markdown('<div class="hr"></div>', unsafe_allow_html=True)

# -----------------------------
# 3) ë¯¸ë¦¬ë³´ê¸°, ì œì™¸, ë‹¤ìš´ë¡œë“œ
# -----------------------------
st.subheader("3) ë¯¸ë¦¬ë³´ê¸° Â· ì œì™¸ Â· ë‹¤ìš´ë¡œë“œ")

if "cuts_items" not in st.session_state:
    st.info("ë¨¼ì € ìœ„ì—ì„œ **â€˜ë³¸ë¬¸ ìƒí’ˆì»· ì¶”ì¶œí•˜ê¸°â€™**ë¥¼ ì‹¤í–‰í•´ ì£¼ì„¸ìš”.")
else:
    base_name = st.session_state.get("cuts_base_name", "misharp_detail")
    crop_mode = st.session_state.get("cuts_crop_mode", "ì´ë¯¸ì§€ ê·¸ëŒ€ë¡œ ìë¥´ê¸°")
    cuts: List[CutItem] = st.session_state.get("cuts_items", [])

    total = len(cuts)
    auto_ex = sum(1 for c in cuts if c.excluded_auto)

    st.markdown(
        f"""
<div class="card">
<b>í˜„ì¬ ìƒíƒœ</b><br/>
- ì¶”ì¶œ í›„ë³´: <b>{total}ê°œ</b><br/>
- ìë™ ì œì™¸(í…ìŠ¤íŠ¸/ë¡œê³  ì¶”ì •): <b>{auto_ex}ê°œ</b><br/>
- ìë¥´ê¸° ëª¨ë“œ: <b>{crop_mode}</b><br/>
- í°ì¤„ ì²˜ë¦¬: <b>{EDGE_WHITE_STRIP_MIN_PX}px ì´ìƒ</b>ì€ ì—¬ë°±ìœ¼ë¡œ ì œê±°
</div>
""",
        unsafe_allow_html=True,
    )

    st.markdown('<div class="hr"></div>', unsafe_allow_html=True)

    st.write("### ì œì™¸í•  ì»· ì„ íƒ")
    st.caption("ìë™ ì œì™¸ê°€ ì˜¤íƒì´ë©´ ì²´í¬ë¥¼ í•´ì œí•˜ê³ , ë¹¼ê³  ì‹¶ì€ ì»·ì€ ì²´í¬í•˜ì„¸ìš”.")

    cols = st.columns(4)
    manual_key_prefix = f"manual_ex_{base_name}_{crop_mode}"

    for i, item in enumerate(cuts):
        col = cols[i % 4]
        key = f"{manual_key_prefix}_{item.idx}"

        if key not in st.session_state:
            st.session_state[key] = bool(item.excluded_auto)

        thumb = item.pil.copy()
        thumb.thumbnail((420, 420))

        with col:
            st.image(thumb, caption=f"#{item.idx} ({item.pil.size[0]}x{item.pil.size[1]})", use_container_width=True)

            label = "ì´ ì»· ì œì™¸"
            if item.excluded_auto and item.reason:
                label += f" (ìë™: {item.reason})"

            st.checkbox(label, key=key)

    # ìˆ˜ë™ ì œì™¸ ì ìš©
    for item in cuts:
        key = f"{manual_key_prefix}_{item.idx}"
        item.excluded_manual = bool(st.session_state.get(key, False))

    final_items = [c for c in cuts if not c.excluded_manual]

    st.markdown('<div class="hr"></div>', unsafe_allow_html=True)

    st.write("### ë‹¤ìš´ë¡œë“œ")
    st.caption("ë‹¤ìš´ë¡œë“œëŠ” â€˜ìµœì¢… í¬í•¨â€™ëœ ì»·ë§Œ ìƒì„±í•©ë‹ˆë‹¤.")
    st.write(f"ìµœì¢… í¬í•¨: **{len(final_items)}ê°œ** / ì œì™¸: **{total - len(final_items)}ê°œ**")

    if len(final_items) == 0:
        st.warning("í¬í•¨ëœ ì»·ì´ 0ê°œì…ë‹ˆë‹¤. ì œì™¸ ì²´í¬ë¥¼ í•´ì œí•´ ì£¼ì„¸ìš”.")
    else:
        col1, col2 = st.columns([1, 1])

        with col1:
            if st.button("ğŸ“¦ ZIP ë§Œë“¤ê¸°(ì „ì²´)", use_container_width=True):
                with st.spinner("ZIP ìƒì„± ì¤‘..."):
                    files: List[Tuple[str, bytes]] = []
                    for n, it in enumerate(final_items, start=1):
                        out = apply_crop_mode(it.pil, crop_mode)
                        fname = f"{safe_filename(base_name)}_{n:03d}.jpg"
                        files.append((fname, pil_to_bytes_jpg(out, quality=95)))

                    zip_bytes = make_download_zip(files)
                    st.session_state["dl_zip"] = zip_bytes
                    st.session_state["dl_zip_name"] = f"{safe_filename(base_name)}_cuts.zip"

        with col2:
            out0 = apply_crop_mode(final_items[0].pil, crop_mode)
            st.download_button(
                "â¬‡ï¸ ëŒ€í‘œ 1ì¥ JPG ë‹¤ìš´ë¡œë“œ(ì²« ì»·)",
                data=pil_to_bytes_jpg(out0, quality=95),
                file_name=f"{safe_filename(base_name)}_001.jpg",
                mime="image/jpeg",
                use_container_width=True,
                key=f"download_first_{base_name}_{crop_mode}",
            )

        if st.session_state.get("dl_zip"):
            st.download_button(
                "â¬‡ï¸ ZIP ë‹¤ìš´ë¡œë“œ",
                data=st.session_state["dl_zip"],
                file_name=st.session_state.get("dl_zip_name", f"{safe_filename(base_name)}_cuts.zip"),
                mime="application/zip",
                use_container_width=True,
                key=f"download_zip_{base_name}_{crop_mode}",
            )

    st.markdown(
        """
<div class="footer-note">
<hr/>
<b>ì €ì‘ê¶Œ / ë³´ì•ˆ ì•ˆë‚´</b><br/>
- (KR) ë³¸ í”„ë¡œê·¸ë¨ì˜ ì €ì‘ê¶Œì€ <b>misharpcompany</b>ì— ìˆìœ¼ë©°, ë¬´ë‹¨ ë³µì œÂ·ë°°í¬Â·ì‚¬ìš©ì„ ê¸ˆí•©ë‹ˆë‹¤.<br/>
- (KR) ë³¸ í”„ë¡œê·¸ë¨ì€ <b>ë¯¸ìƒµì»´í¼ë‹ˆ ì§ì› ì „ìš©</b>ì´ë©°, ì™¸ë¶€ë¡œ ìœ ì¶œí•˜ê±°ë‚˜ ì œ3ìì—ê²Œ ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.<br/><br/>
- (EN) Copyright of this program belongs to <b>misharpcompany</b>. Unauthorized copying, distribution, or use is prohibited.<br/>
- (EN) This program is <b>for misharpcompany staff only</b> and must not be shared externally or provided to third parties.
</div>
""",
        unsafe_allow_html=True,
    )
