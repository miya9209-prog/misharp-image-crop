# app.py
# -*- coding: utf-8 -*-

import io
import re
import zipfile
from dataclasses import dataclass
from typing import List, Tuple, Optional

import numpy as np
import requests
import streamlit as st
from bs4 import BeautifulSoup
from PIL import Image

# -----------------------------
# ê¸°ë³¸ ì„¤ì •
# -----------------------------
st.set_page_config(
    page_title="ë¯¸ìƒµ ìƒì„¸í˜ì´ì§€ ì´ë¯¸ì§€ ì¶”ì¶œê¸°",
    page_icon="ğŸ§©",
    layout="wide",
)

USER_AGENT = (
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
    "AppleWebKit/537.36 (KHTML, like Gecko) "
    "Chrome/122.0.0.0 Safari/537.36"
)

# -----------------------------
# ë°ì´í„° êµ¬ì¡°
# -----------------------------
@dataclass
class CutItem:
    idx: int
    pil: Image.Image
    excluded_auto: bool = False
    excluded_manual: bool = False
    reason: str = ""


# -----------------------------
# ìœ í‹¸
# -----------------------------
def safe_filename(name: str) -> str:
    name = (name or "").strip()
    name = re.sub(r"[\\/:*?\"<>|]+", "_", name)
    name = re.sub(r"\s+", " ", name).strip()
    return name[:120] if len(name) > 120 else name


def pil_to_bytes_jpg(img: Image.Image, quality: int = 95) -> bytes:
    buf = io.BytesIO()
    img.save(buf, format="JPEG", quality=quality, optimize=True)
    return buf.getvalue()


def center_crop_to_aspect(img: Image.Image, target_aspect: float) -> Image.Image:
    """ì™œê³¡ ì—†ì´ ê°€ìš´ë° ê¸°ì¤€ìœ¼ë¡œ ë¹„ìœ¨ ë§ì¶”ê¸°(ì˜ë¼ë‚´ê¸°)."""
    w, h = img.size
    if w <= 0 or h <= 0:
        return img

    cur_aspect = w / float(h)
    if abs(cur_aspect - target_aspect) < 1e-6:
        return img

    if cur_aspect > target_aspect:
        new_w = int(round(h * target_aspect))
        new_w = max(1, min(new_w, w))
        left = (w - new_w) // 2
        return img.crop((left, 0, left + new_w, h))
    else:
        new_h = int(round(w / target_aspect))
        new_h = max(1, min(new_h, h))
        top = (h - new_h) // 2
        return img.crop((0, top, w, top + new_h))


def trim_white_margin(img: Image.Image, white_thr: int = 245, pad: int = 2) -> Image.Image:
    """í° ë°°ê²½ ì—¬ë°± ì œê±°."""
    if img.mode != "RGB":
        img = img.convert("RGB")

    arr = np.array(img)
    is_white = (arr[:, :, 0] >= white_thr) & (arr[:, :, 1] >= white_thr) & (arr[:, :, 2] >= white_thr)
    non_white = ~is_white

    if not np.any(non_white):
        return img

    ys, xs = np.where(non_white)
    y0, y1 = ys.min(), ys.max()
    x0, x1 = xs.min(), xs.max()

    y0 = max(0, y0 - pad)
    x0 = max(0, x0 - pad)
    y1 = min(arr.shape[0] - 1, y1 + pad)
    x1 = min(arr.shape[1] - 1, x1 + pad)

    return img.crop((x0, y0, x1 + 1, y1 + 1))


def row_nonwhite_ratio(arr_rgb: np.ndarray, white_thr: int = 245) -> np.ndarray:
    is_white = (arr_rgb[:, :, 0] >= white_thr) & (arr_rgb[:, :, 1] >= white_thr) & (arr_rgb[:, :, 2] >= white_thr)
    non_white = ~is_white
    return non_white.mean(axis=1).astype(np.float32)


def smooth_1d(x: np.ndarray, k: int = 31) -> np.ndarray:
    if k <= 1:
        return x
    k = int(k)
    k = k if k % 2 == 1 else k + 1
    pad = k // 2
    xp = np.pad(x, (pad, pad), mode="edge")
    kernel = np.ones(k, dtype=np.float32) / k
    return np.convolve(xp, kernel, mode="valid")


def find_separator_gaps(ratio: np.ndarray, gap_thr: float = 0.006, min_gap: int = 20) -> List[Tuple[int, int]]:
    low = ratio <= gap_thr
    gaps = []
    start = None
    for i, v in enumerate(low):
        if v and start is None:
            start = i
        elif (not v) and start is not None:
            end = i - 1
            if end - start + 1 >= min_gap:
                gaps.append((start, end))
            start = None
    if start is not None:
        end = len(low) - 1
        if end - start + 1 >= min_gap:
            gaps.append((start, end))
    return gaps


def segment_long_detail_image(img: Image.Image) -> List[Image.Image]:
    """ê¸´ ìƒì„¸í˜ì´ì§€ JPGë¥¼ í° ì—¬ë°± êµ¬ê°„ ê¸°ì¤€ìœ¼ë¡œ ì»· ë¶„ë¦¬."""
    if img.mode != "RGB":
        img = img.convert("RGB")

    arr = np.array(img)
    r = row_nonwhite_ratio(arr, white_thr=245)
    r = smooth_1d(r, k=31)

    gaps = find_separator_gaps(r, gap_thr=0.006, min_gap=20)

    h = arr.shape[0]
    cuts = []
    prev_end = -1
    for (g0, g1) in gaps:
        seg_top = prev_end + 1
        seg_bot = g0 - 1
        if seg_bot - seg_top + 1 >= 80:
            cuts.append((seg_top, seg_bot))
        prev_end = g1

    if prev_end < h - 1:
        seg_top = prev_end + 1
        seg_bot = h - 1
        if seg_bot - seg_top + 1 >= 80:
            cuts.append((seg_top, seg_bot))

    out = []
    w = img.size[0]
    for (t, b) in cuts:
        seg = img.crop((0, t, w, b + 1))
        seg = trim_white_margin(seg, white_thr=245, pad=2)
        if seg.size[1] < 120 or seg.size[0] < 200:
            continue
        out.append(seg)

    return out


def looks_like_text_card(img: Image.Image) -> Tuple[bool, str]:
    """í…ìŠ¤íŠ¸/íƒ€ì´í‹€/ì•„ì´ì½˜ ì»· ìë™ ì œì™¸ìš©."""
    if img.mode != "RGB":
        img = img.convert("RGB")
    w, h = img.size
    arr = np.array(img).astype(np.uint8)

    white = (arr[:, :, 0] >= 245) & (arr[:, :, 1] >= 245) & (arr[:, :, 2] >= 245)
    white_ratio = float(white.mean())

    gray = (0.299 * arr[:, :, 0] + 0.587 * arr[:, :, 1] + 0.114 * arr[:, :, 2]).astype(np.float32)
    dark_ratio = float((gray < 80).mean())

    std = float(arr.reshape(-1, 3).std(axis=0).mean())

    if h < 220 and white_ratio > 0.75 and dark_ratio > 0.002:
        return True, "í…ìŠ¤íŠ¸ ì•ˆë‚´(ì–‡ì€ ë )ë¡œ ì¶”ì •"

    if white_ratio > 0.70 and 0.002 < dark_ratio < 0.18 and std < 35:
        return True, "í…ìŠ¤íŠ¸/íƒ€ì´í‹€ ì»·ìœ¼ë¡œ ì¶”ì •"

    if (h < 500 and w < 900) and white_ratio > 0.40 and dark_ratio < 0.10:
        return True, "ì•„ì´ì½˜/ë¡œê³ ì„± ì´ë¯¸ì§€ë¡œ ì¶”ì •"

    return False, ""


def apply_crop_mode(img: Image.Image, mode: str) -> Image.Image:
    """4ê°€ì§€ ìë¥´ê¸° ëª¨ë“œ ì ìš©."""
    base = trim_white_margin(img, white_thr=245, pad=2)

    if mode == "ì´ë¯¸ì§€ ê·¸ëŒ€ë¡œ ìë¥´ê¸°":
        return base

    if mode == "ì¸ìŠ¤íƒ€ê·¸ë¨ í”¼ë“œ ê·œê²©(4:5)":
        out = center_crop_to_aspect(base, 4 / 5)
        return out.resize((1080, 1350), Image.LANCZOS)

    if mode == "ì •ë°©í˜•(1:1)":
        out = center_crop_to_aspect(base, 1.0)
        return out.resize((1080, 1080), Image.LANCZOS)

    if mode == "ìˆí¼ê·œê²©(900x1600)":
        out = center_crop_to_aspect(base, 900 / 1600)
        return out.resize((900, 1600), Image.LANCZOS)

    return base


def make_download_zip(files: List[Tuple[str, bytes]]) -> bytes:
    buf = io.BytesIO()
    with zipfile.ZipFile(buf, "w", compression=zipfile.ZIP_DEFLATED) as zf:
        for fname, data in files:
            zf.writestr(fname, data)
    return buf.getvalue()


# -----------------------------
# URLì—ì„œ "ë³¸ë¬¸ ìƒì„¸ì´ë¯¸ì§€" í›„ë³´ë§Œ ì°¾ê¸°
# -----------------------------
def normalize_url(url: str) -> str:
    url = (url or "").strip()
    if not url:
        return url
    if not re.match(r"^https?://", url, re.I):
        url = "https://" + url
    return url


def fetch_html(url: str, timeout: int = 15) -> str:
    headers = {"User-Agent": USER_AGENT}
    r = requests.get(url, headers=headers, timeout=timeout)
    r.raise_for_status()
    return r.text


def is_image_url(u: str) -> bool:
    u_low = u.lower()
    return any(u_low.endswith(ext) for ext in [".jpg", ".jpeg", ".png", ".webp", ".gif"])


def absolutize(base_url: str, src: str) -> str:
    src = (src or "").strip()
    if src.startswith("//"):
        return "https:" + src
    if src.startswith("http://") or src.startswith("https://"):
        return src
    if src.startswith("/"):
        m = re.match(r"^(https?://[^/]+)", base_url)
        return (m.group(1) if m else base_url.rstrip("/")) + src
    return base_url.rstrip("/") + "/" + src.lstrip("/")


def pick_body_image_urls_from_html(product_url: str, html: str) -> List[str]:
    soup = BeautifulSoup(html, "html.parser")

    selectors = [
        "#prdDetail", "#prdDetailContent", "#prdDetailCont",
        "#productDetail", "#product_detail", "#contents",
        ".prdDetail", ".prdDetailContent", ".productDetail",
        "#tabProductDetail", "#tabDetail",
        "div[id*='prdDetail']", "div[class*='prdDetail']",
    ]

    img_urls: List[str] = []
    for sel in selectors:
        node = soup.select_one(sel)
        if not node:
            continue
        for img in node.select("img"):
            src = img.get("src") or img.get("data-src") or img.get("ec-data-src")
            if not src:
                continue
            src = absolutize(product_url, src)
            if is_image_url(src):
                img_urls.append(src)

    img_urls = list(dict.fromkeys(img_urls))

    if not img_urls:
        all_imgs = soup.select("img")
        tmp = []
        for img in all_imgs:
            src = img.get("src") or img.get("data-src") or img.get("ec-data-src")
            if not src:
                continue
            src = absolutize(product_url, src)
            if not is_image_url(src):
                continue

            s_low = src.lower()
            if any(k in s_low for k in ["icon", "logo", "sprite", "common", "btn", "banner"]):
                continue

            tmp.append(src)
        img_urls = list(dict.fromkeys(tmp))

    return img_urls


def download_image(url: str, timeout: int = 20) -> Optional[Image.Image]:
    headers = {"User-Agent": USER_AGENT}
    try:
        r = requests.get(url, headers=headers, timeout=timeout)
        r.raise_for_status()
        img = Image.open(io.BytesIO(r.content))
        return img.convert("RGB")
    except Exception:
        return None


def fetch_detail_images_from_product_url(product_url: str) -> List[Image.Image]:
    html = fetch_html(product_url)
    candidates = pick_body_image_urls_from_html(product_url, html)

    downloaded: List[Image.Image] = []
    for u in candidates:
        im = download_image(u)
        if im is not None:
            downloaded.append(im)

    # ê¸´ ìƒì„¸ì´ë¯¸ì§€ ìš°ì„ 
    long_imgs = []
    for im in downloaded:
        w, h = im.size
        if h > w * 2 and h > 2000:
            long_imgs.append(im)

    if not long_imgs:
        big_imgs = []
        for im in downloaded:
            w, h = im.size
            if min(w, h) >= 700 and (h >= 900 or w >= 900):
                big_imgs.append(im)
        long_imgs = big_imgs[:30]

    return long_imgs


def guess_base_name_from_url(url: str) -> str:
    m = re.search(r"product_no=(\d+)", url)
    if m:
        return f"product_{m.group(1)}"
    base = re.sub(r"[?#].*$", "", url).rstrip("/").split("/")[-1]
    return safe_filename(base or "misharp_detail")


# -----------------------------
# ì»· ìƒì„± íŒŒì´í”„ë¼ì¸
# -----------------------------
def build_items_from_sources(source_images: List[Image.Image], auto_exclude_text: bool = True) -> List[CutItem]:
    all_items: List[CutItem] = []
    global_idx = 1

    for img in source_images:
        w, h = img.size
        if h > w * 2 and h > 2000:
            segs = segment_long_detail_image(img)
            for seg in segs:
                ex = False
                reason = ""
                if auto_exclude_text:
                    ex, reason = looks_like_text_card(seg)
                all_items.append(CutItem(idx=global_idx, pil=seg, excluded_auto=ex, reason=reason))
                global_idx += 1
        else:
            seg = trim_white_margin(img, white_thr=245, pad=2)
            ex = False
            reason = ""
            if auto_exclude_text:
                ex, reason = looks_like_text_card(seg)
            all_items.append(CutItem(idx=global_idx, pil=seg, excluded_auto=ex, reason=reason))
            global_idx += 1

    # ì•ˆì „ì¥ì¹˜: ë„ˆë¬´ ì‘ì€ ì¡°ê° ìë™ ì œì™¸
    for it in all_items:
        ww, hh = it.pil.size
        if ww < 300 or hh < 200:
            it.excluded_auto = True
            it.reason = it.reason or "ë„ˆë¬´ ì‘ì€ ì´ë¯¸ì§€(ì¡°ê°)ë¡œ ì œì™¸"

    return all_items


# -----------------------------
# UI ìŠ¤íƒ€ì¼
# -----------------------------
st.markdown(
    """
<style>
.block-container { padding-top: 1.1rem; padding-bottom: 2.4rem; }
.card { border:1px solid #eee; border-radius:12px; padding:14px; background:#fff; }
.hr { height:1px; background:#eee; margin:14px 0; }
.small-note { font-size: 12px; color: #666; }
.footer-note { font-size: 11px; color:#777; line-height: 1.55; padding-top: 18px; }
</style>
""",
    unsafe_allow_html=True,
)

st.title("ğŸ§© ìƒì„¸í˜ì´ì§€ ì´ë¯¸ì§€ ì¶”ì¶œê¸°")
st.caption("ë¯¸ìƒµ ìƒí’ˆ URL ë˜ëŠ” ìƒì„¸í˜ì´ì§€ JPG(ê¸´ ì´ë¯¸ì§€)ë¥¼ ë„£ìœ¼ë©´, ë³¸ë¬¸ ìƒí’ˆì»·ë§Œ ìë™ ë¶„ë¦¬/í¬ë¡­í•˜ì—¬ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.")

tab1, tab2 = st.tabs(["ì—…ë¡œë“œ", "ë¯¸ë¦¬ë³´ê¸° Â· ì œì™¸ Â· ë‹¤ìš´ë¡œë“œ"])

with tab1:
    st.subheader("1) ì…ë ¥ ë°©ì‹")
    colA, colB = st.columns([1.25, 1])

    with colA:
        input_type = st.radio("ì…ë ¥ ì„ íƒ", ["ìƒí’ˆ URL", "ìƒì„¸í˜ì´ì§€ JPG ì—…ë¡œë“œ"], horizontal=True)

        product_url = ""
        uploaded_files = None

        if input_type == "ìƒí’ˆ URL":
            product_url = st.text_input(
                "ë¯¸ìƒµ ìƒí’ˆ URL",
                placeholder="https://misharp.co.kr/product/detail.html?product_no=XXXXX ...",
            )
            st.markdown(
                '<div class="small-note">â€» URL ì…ë ¥ ì‹œ: <b>ìƒí’ˆ ìƒì„¸ HTMLì—ì„œ ë³¸ë¬¸ ìƒì„¸ì´ë¯¸ì§€ í›„ë³´ë§Œ</b> ì„ ë³„í•´ ì²˜ë¦¬í•©ë‹ˆë‹¤.</div>',
                unsafe_allow_html=True,
            )
        else:
            uploaded_files = st.file_uploader(
                "ìƒì„¸í˜ì´ì§€ JPG ì—…ë¡œë“œ (ì—¬ëŸ¬ ì¥ ê°€ëŠ¥)",
                type=["jpg", "jpeg"],
                accept_multiple_files=True,
                help="ê¸´ ìƒì„¸í˜ì´ì§€ ì´ë¯¸ì§€ 1ì¥ ë˜ëŠ” ì—¬ëŸ¬ ì¥ì„ ì˜¬ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            )

    with colB:
        st.subheader("2) ìë¥´ê¸° ì˜µì…˜")
        crop_mode = st.selectbox(
            "ìë¥´ê¸° ëª¨ë“œ",
            [
                "ì´ë¯¸ì§€ ê·¸ëŒ€ë¡œ ìë¥´ê¸°",
                "ì¸ìŠ¤íƒ€ê·¸ë¨ í”¼ë“œ ê·œê²©(4:5)",
                "ì •ë°©í˜•(1:1)",
                "ìˆí¼ê·œê²©(900x1600)",
            ],
            index=0,
        )
        auto_exclude_text = st.checkbox("í…ìŠ¤íŠ¸/íƒ€ì´í‹€/ë¡œê³  ì»· ìë™ ì œì™¸", value=True)
        st.markdown('<div class="small-note">â€» ë‹¤ìŒ íƒ­ì—ì„œ ìˆ˜ë™ ì²´í¬ë¡œ ì œì™¸/í¬í•¨ì„ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</div>', unsafe_allow_html=True)

    st.markdown('<div class="hr"></div>', unsafe_allow_html=True)

    run = st.button("âœ… ë³¸ë¬¸ ìƒí’ˆì»· ì¶”ì¶œí•˜ê¸°", type="primary", use_container_width=True)

    if run:
        with st.spinner("ì´ë¯¸ì§€ ìˆ˜ì§‘/ë¶„ì„ ì¤‘..."):
            base_name = "misharp_detail"
            source_images: List[Image.Image] = []

            if input_type == "ìƒí’ˆ URL":
                product_url = normalize_url(product_url)
                if not product_url:
                    st.error("ìƒí’ˆ URLì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
                    st.stop()

                base_name = guess_base_name_from_url(product_url)
                imgs = fetch_detail_images_from_product_url(product_url)

                if not imgs:
                    st.error("ë³¸ë¬¸ ìƒì„¸ì´ë¯¸ì§€ë¥¼ ì°¾ì§€ ëª»í–ˆì–´ìš”. (ì ‘ê·¼ ì œí•œ/ë³¸ë¬¸ ì´ë¯¸ì§€ê°€ ë‹¤ë¥¸ ë°©ì‹ì¼ ìˆ˜ ìˆìŒ)")
                    st.stop()

                source_images = imgs

            else:
                if not uploaded_files or len(uploaded_files) == 0:
                    st.error("ìƒì„¸í˜ì´ì§€ JPGë¥¼ 1ì¥ ì´ìƒ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
                    st.stop()

                first_name = uploaded_files[0].name
                base_name = safe_filename(re.sub(r"\.(jpg|jpeg)$", "", first_name, flags=re.I)) or "misharp_detail"

                for f in uploaded_files:
                    try:
                        im = Image.open(f).convert("RGB")
                        source_images.append(im)
                    except Exception:
                        continue

                if not source_images:
                    st.error("ì—…ë¡œë“œí•œ íŒŒì¼ì„ ì´ë¯¸ì§€ë¡œ ì½ì§€ ëª»í–ˆì–´ìš”.")
                    st.stop()

            items = build_items_from_sources(source_images, auto_exclude_text=auto_exclude_text)

            if not items:
                st.error("ì¶”ì¶œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                st.stop()

            st.session_state["cuts_base_name"] = base_name
            st.session_state["cuts_crop_mode"] = crop_mode
            st.session_state["cuts_items"] = items
            # ì´ì „ zip ìºì‹œ ì œê±°
            st.session_state.pop("dl_zip", None)
            st.session_state.pop("dl_zip_name", None)

        st.success(f"ì¶”ì¶œ ì™„ë£Œ! (ì´ {len(items)}ê°œ í›„ë³´) â†’ ë‹¤ìŒ íƒ­ì—ì„œ ë¯¸ë¦¬ë³´ê¸°/ì œì™¸/ë‹¤ìš´ë¡œë“œë¥¼ ì§„í–‰í•˜ì„¸ìš”.")

with tab2:
    st.subheader("ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸° Â· ì œì™¸ Â· ë‹¤ìš´ë¡œë“œ")

    if "cuts_items" not in st.session_state:
        st.info("ë¨¼ì € **ì—…ë¡œë“œ íƒ­**ì—ì„œ â€˜ë³¸ë¬¸ ìƒí’ˆì»· ì¶”ì¶œí•˜ê¸°â€™ë¥¼ ì‹¤í–‰í•´ ì£¼ì„¸ìš”.")
    else:
        base_name = st.session_state.get("cuts_base_name", "misharp_detail")
        crop_mode = st.session_state.get("cuts_crop_mode", "ì´ë¯¸ì§€ ê·¸ëŒ€ë¡œ ìë¥´ê¸°")
        cuts: List[CutItem] = st.session_state.get("cuts_items", [])

        total = len(cuts)
        auto_ex = sum(1 for c in cuts if c.excluded_auto)

        st.markdown(
            f"""
<div class="card">
<b>í˜„ì¬ ìƒíƒœ</b><br/>
- ì¶”ì¶œ í›„ë³´: <b>{total}ê°œ</b><br/>
- ìë™ ì œì™¸(í…ìŠ¤íŠ¸/ë¡œê³  ì¶”ì •): <b>{auto_ex}ê°œ</b><br/>
- ìë¥´ê¸° ëª¨ë“œ: <b>{crop_mode}</b>
</div>
""",
            unsafe_allow_html=True,
        )

        st.markdown('<div class="hr"></div>', unsafe_allow_html=True)

        st.write("### 2) ì œì™¸í•  ì»· ì„ íƒ")
        st.caption("ìë™ ì œì™¸ê°€ ì˜¤íƒì´ë©´ ì²´í¬ë¥¼ í•´ì œí•˜ê³ , ë¹¼ê³  ì‹¶ì€ ì»·ì€ ì²´í¬í•˜ì„¸ìš”.")

        cols = st.columns(4)
        manual_key_prefix = f"manual_ex_{base_name}_{crop_mode}"

        for i, item in enumerate(cuts):
            col = cols[i % 4]

            key = f"{manual_key_prefix}_{item.idx}"

            # ìµœì´ˆ 1íšŒë§Œ ê¸°ë³¸ê°’ ì„¸íŒ…(ì§ì ‘ set ê°€ëŠ¥: ìœ„ì ¯ ìƒì„± ì „ì´ë¯€ë¡œ ì•ˆì „)
            if key not in st.session_state:
                st.session_state[key] = bool(item.excluded_auto)

            thumb = item.pil.copy()
            thumb.thumbnail((360, 360))

            with col:
                st.image(thumb, caption=f"#{item.idx} ({item.pil.size[0]}x{item.pil.size[1]})", use_container_width=True)
                label = "ì´ ì»· ì œì™¸"
                if item.excluded_auto and item.reason:
                    label += f" (ìë™: {item.reason})"

                # âœ… í•µì‹¬ ìˆ˜ì •: checkbox ë°˜í™˜ê°’ì„ session_stateì— ì§ì ‘ ëŒ€ì…í•˜ì§€ ì•ŠìŒ
                st.checkbox(label, key=key)

        # ìˆ˜ë™ ì œì™¸ ì ìš©
        for item in cuts:
            key = f"{manual_key_prefix}_{item.idx}"
            item.excluded_manual = bool(st.session_state.get(key, False))

        final_items = [c for c in cuts if not c.excluded_manual]

        st.markdown('<div class="hr"></div>', unsafe_allow_html=True)

        st.write("### 3) ë‹¤ìš´ë¡œë“œ")
        st.caption("ë‹¤ìš´ë¡œë“œëŠ” â€˜ìµœì¢… í¬í•¨â€™ëœ ì»·ë§Œ ìƒì„±í•©ë‹ˆë‹¤.")
        st.write(f"ìµœì¢… í¬í•¨: **{len(final_items)}ê°œ** / ì œì™¸: **{total - len(final_items)}ê°œ**")

        if len(final_items) == 0:
            st.warning("í¬í•¨ëœ ì»·ì´ 0ê°œì…ë‹ˆë‹¤. ì œì™¸ ì²´í¬ë¥¼ í•´ì œí•´ ì£¼ì„¸ìš”.")
        else:
            col1, col2 = st.columns([1, 1])

            with col1:
                if st.button("ğŸ“¦ ZIP ë§Œë“¤ê¸°(ì „ì²´)", use_container_width=True):
                    with st.spinner("ZIP ìƒì„± ì¤‘..."):
                        files: List[Tuple[str, bytes]] = []
                        for n, it in enumerate(final_items, start=1):
                            out = apply_crop_mode(it.pil, crop_mode)
                            fname = f"{safe_filename(base_name)}_{n:03d}.jpg"
                            files.append((fname, pil_to_bytes_jpg(out, quality=95)))

                        zip_bytes = make_download_zip(files)
                        st.session_state["dl_zip"] = zip_bytes
                        st.session_state["dl_zip_name"] = f"{safe_filename(base_name)}_cuts.zip"

            with col2:
                out0 = apply_crop_mode(final_items[0].pil, crop_mode)
                st.download_button(
                    "â¬‡ï¸ ëŒ€í‘œ 1ì¥ JPG ë‹¤ìš´ë¡œë“œ(ì²« ì»·)",
                    data=pil_to_bytes_jpg(out0, quality=95),
                    file_name=f"{safe_filename(base_name)}_001.jpg",
                    mime="image/jpeg",
                    use_container_width=True,
                    key=f"download_first_{base_name}_{crop_mode}",
                )

            if st.session_state.get("dl_zip"):
                st.download_button(
                    "â¬‡ï¸ ZIP ë‹¤ìš´ë¡œë“œ",
                    data=st.session_state["dl_zip"],
                    file_name=st.session_state.get("dl_zip_name", f"{safe_filename(base_name)}_cuts.zip"),
                    mime="application/zip",
                    use_container_width=True,
                    key=f"download_zip_{base_name}_{crop_mode}",
                )

        # âœ… í•˜ë‹¨ ë¬¸êµ¬ëŠ” ì–´ë–¤ ê²½ìš°ì—ë„ ë³´ì´ë„ë¡ stop() ì—†ì´ í•­ìƒ ì¶œë ¥
        st.markdown(
            """
<div class="footer-note">
<hr/>
<b>ì €ì‘ê¶Œ / ë³´ì•ˆ ì•ˆë‚´</b><br/>
- (KR) ë³¸ í”„ë¡œê·¸ë¨ì˜ ì €ì‘ê¶Œì€ <b>misharpcompany</b>ì— ìˆìœ¼ë©°, ë¬´ë‹¨ ë³µì œÂ·ë°°í¬Â·ì‚¬ìš©ì„ ê¸ˆí•©ë‹ˆë‹¤.<br/>
- (KR) ë³¸ í”„ë¡œê·¸ë¨ì€ <b>ë¯¸ìƒµì»´í¼ë‹ˆ ì§ì› ì „ìš©</b>ì´ë©°, ì™¸ë¶€ë¡œ ìœ ì¶œí•˜ê±°ë‚˜ ì œ3ìì—ê²Œ ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.<br/><br/>
- (EN) Copyright of this program belongs to <b>misharpcompany</b>. Unauthorized copying, distribution, or use is prohibited.<br/>
- (EN) This program is <b>for misharpcompany staff only</b> and must not be shared externally or provided to third parties.
</div>
""",
            unsafe_allow_html=True,
        )
